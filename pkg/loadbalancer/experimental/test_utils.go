// SPDX-License-Identifier: Apache-2.0
// Copyright Authors of Cilium

package experimental

import (
	"bytes"
	"fmt"
	"net"
	"net/netip"
	"os"
	"path"
	"regexp"
	"slices"
	"sort"
	"strconv"
	"strings"
	"testing"

	"github.com/cilium/statedb"
	"github.com/cilium/statedb/reconciler"
	"github.com/pmezard/go-difflib/difflib"
	"github.com/stretchr/testify/require"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	k8sRuntime "k8s.io/apimachinery/pkg/runtime"
	"k8s.io/apimachinery/pkg/runtime/serializer"

	"github.com/cilium/cilium/pkg/clustermesh/types"
	"github.com/cilium/cilium/pkg/k8s/resource"
	slim_corev1 "github.com/cilium/cilium/pkg/k8s/slim/k8s/api/core/v1"
	slim_fake "github.com/cilium/cilium/pkg/k8s/slim/k8s/client/clientset/versioned/fake"
	"github.com/cilium/cilium/pkg/loadbalancer"
	"github.com/cilium/cilium/pkg/maps/lbmap"
)

var (
	slimDecoder k8sRuntime.Decoder
)

func init() {
	slimScheme := k8sRuntime.NewScheme()
	slim_fake.AddToScheme(slimScheme)
	slimScheme.AddKnownTypes(slim_corev1.SchemeGroupVersion, &metav1.List{})
	slimDecoder = serializer.NewCodecFactory(slimScheme).UniversalDeserializer()
}

var (
	// special addresses that are replaced by the test runner.
	autoAddr = loadbalancer.L3n4Addr{
		AddrCluster: types.MustParseAddrCluster("0.0.0.1"),
		L4Addr:      loadbalancer.L4Addr{},
		Scope:       0,
	}
	zeroAddr = loadbalancer.L3n4Addr{
		AddrCluster: types.MustParseAddrCluster("0.0.0.3"),
		L4Addr:      loadbalancer.L4Addr{},
		Scope:       0,
	}

	extraFrontend = loadbalancer.L3n4Addr{
		AddrCluster: types.MustParseAddrCluster("10.0.0.2"),
		L4Addr: loadbalancer.L4Addr{
			Protocol: loadbalancer.TCP,
			Port:     80,
		},
		Scope: 0,
	}

	// backend addresses
	backend1 = loadbalancer.L3n4Addr{
		AddrCluster: types.MustParseAddrCluster("10.1.0.1"),
		L4Addr: loadbalancer.L4Addr{
			Protocol: loadbalancer.TCP,
			Port:     80,
		},
		Scope: 0,
	}
	backend2 = loadbalancer.L3n4Addr{
		AddrCluster: types.MustParseAddrCluster("10.1.0.2"),
		L4Addr: loadbalancer.L4Addr{
			Protocol: loadbalancer.TCP,
			Port:     80,
		},
		Scope: 0,
	}

	// frontendAddrs are assigned to the <auto>/autoAddr. Each test set is run with
	// each of these.
	frontendAddrs = []loadbalancer.L3n4Addr{
		parseAddrPort("10.0.0.1:80"),
		parseAddrPort("[2001::1]:80"),
	}

	nodePortAddrs = []netip.Addr{
		netip.MustParseAddr("10.0.0.3"),
		netip.MustParseAddr("2002::1"),
	}
)

func decodeObject[Obj k8sRuntime.Object](t *testing.T, file string) Obj {
	bytes, err := os.ReadFile(file)
	require.NoError(t, err, "ReadFile(%s)", file)
	obj, _, err := slimDecoder.Decode(bytes, nil, nil)
	require.NoError(t, err, "Decode(%s)", file)
	return obj.(Obj)
}

func readObjects[Obj k8sRuntime.Object](t *testing.T, dataDir string, prefix string) (out []Obj) {
	ents, err := os.ReadDir(dataDir)
	require.NoError(t, err, "ReadDir(%s)", dataDir)

	for _, ent := range ents {
		if strings.HasPrefix(ent.Name(), prefix) && strings.HasSuffix(ent.Name(), ".yaml") {
			out = append(out, decodeObject[Obj](t, path.Join(dataDir, ent.Name())))
		}
	}
	return
}

func upsertEvent[Obj k8sRuntime.Object](obj Obj) resource.Event[Obj] {
	return resource.Event[Obj]{
		Object: obj,
		Key:    resource.NewKey(obj),
		Kind:   resource.Upsert,
		Done:   func(error) {},
	}
}

func deleteEvent[Obj k8sRuntime.Object](obj Obj) resource.Event[Obj] {
	return resource.Event[Obj]{
		Object: obj,
		Key:    resource.NewKey(obj),
		Kind:   resource.Delete,
		Done:   func(error) {},
	}
}

type numeric interface {
	~int | ~uint32 | ~uint16
}

// TODO: Figure out what to do about the IDs. If we want to do fault inject the
// operations will be retried and the ID allocations are non-deterministic.
func sanitizeID[Num numeric](n Num, sanitize bool) string {
	if !sanitize {
		return strconv.FormatInt(int64(n), 10)
	}
	if n == 0 {
		return "<zero>"
	}
	return "<non-zero>"
}

func parseAddrPort(s string) loadbalancer.L3n4Addr {
	addrS, portS, found := strings.Cut(s, "]:")
	if found {
		// IPv6
		addrS = addrS[1:] // drop [
	} else {
		// IPv4
		addrS, portS, found = strings.Cut(s, ":")
		if !found {
			panic("bad <ip:port>")
		}
	}
	addr := types.MustParseAddrCluster(addrS)
	port, _ := strconv.ParseInt(portS, 10, 16)
	return *loadbalancer.NewL3n4Addr(
		loadbalancer.TCP,
		addr, uint16(port), loadbalancer.ScopeExternal,
	)

}

// mapDump is a dump of a BPF map. These are generated by the dump() method, which
// solely defines the format.
type mapDump = string

// dump the load-balancing maps into a concise format for assertions in tests.
func dump(lbmaps lbmaps, feAddr loadbalancer.L3n4Addr, sanitizeIDs bool) (out []mapDump) {
	out = []string{}

	replaceAddr := func(addr net.IP, port uint16) (s string) {
		if addr.IsUnspecified() {
			s = "<zero>"
			return
		}
		switch addr.String() {
		case feAddr.AddrCluster.String():
			s = "<auto>"
		case nodePortAddrs[0].String():
			s = "<nodePort>"
		case nodePortAddrs[1].String():
			s = "<nodePort>"
		default:
			s = addr.String()
			if addr.To4() == nil {
				s = "[" + s + "]"
			}
			s = fmt.Sprintf("%s:%d", s, port)
		}
		return
	}

	svcCB := func(svcKey lbmap.ServiceKey, svcValue lbmap.ServiceValue) {
		svcKey = svcKey.ToHost()
		svcValue = svcValue.ToHost()
		addr := svcKey.GetAddress()
		addrS := replaceAddr(addr, svcKey.GetPort())
		if svcKey.GetScope() == loadbalancer.ScopeInternal {
			addrS += "/i"
		}
		out = append(out, fmt.Sprintf("SVC: ID=%s ADDR=%s SLOT=%d BEID=%s COUNT=%d QCOUNT=%d FLAGS=%s",
			sanitizeID(svcValue.GetRevNat(), sanitizeIDs),
			addrS,
			svcKey.GetBackendSlot(),
			sanitizeID(svcValue.GetBackendID(), sanitizeIDs),
			svcValue.GetCount(),
			svcValue.GetQCount(),
			strings.ReplaceAll(
				loadbalancer.ServiceFlags(svcValue.GetFlags()).String(),
				", ", "+"),
		))
	}
	if err := lbmaps.DumpService(svcCB); err != nil {
		panic(err)
	}

	beCB := func(beKey lbmap.BackendKey, beValue lbmap.BackendValue) {
		beValue = beValue.ToHost()
		addr := beValue.GetAddress()
		addrS := addr.String()
		if addr.To4() == nil {
			addrS = "[" + addrS + "]"
		}
		stateS, _ := loadbalancer.GetBackendStateFromFlags(beValue.GetFlags()).String()
		out = append(out, fmt.Sprintf("BE: ID=%s ADDR=%s:%d STATE=%s",
			sanitizeID(beKey.GetID(), sanitizeIDs),
			addrS,
			beValue.GetPort(),
			stateS,
		))
	}
	if err := lbmaps.DumpBackend(beCB); err != nil {
		panic(err)
	}

	revCB := func(revKey lbmap.RevNatKey, revValue lbmap.RevNatValue) {
		revKey = revKey.ToHost()
		revValue = revValue.ToHost()

		var addr string

		switch v := revValue.(type) {
		case *lbmap.RevNat4Value:
			addr = replaceAddr(v.Address.IP(), v.Port)

		case *lbmap.RevNat6Value:
			addr = replaceAddr(v.Address.IP(), v.Port)
		}

		out = append(out, fmt.Sprintf("REV: ID=%s ADDR=%s",
			sanitizeID(revKey.GetKey(), sanitizeIDs),
			addr,
		))
	}
	if err := lbmaps.DumpRevNat(revCB); err != nil {
		panic(err)
	}

	affCB := func(affKey *lbmap.AffinityMatchKey, _ *lbmap.AffinityMatchValue) {
		affKey = affKey.ToHost()
		out = append(out, fmt.Sprintf("AFF: ID=%s BEID=%d",
			sanitizeID(affKey.RevNATID, sanitizeIDs),
			affKey.BackendID,
		))
	}

	if err := lbmaps.DumpAffinityMatch(affCB); err != nil {
		panic(err)
	}

	srcRangeCB := func(key lbmap.SourceRangeKey, _ *lbmap.SourceRangeValue) {
		key = key.ToHost()
		out = append(out, fmt.Sprintf("SRCRANGE: ID=%s CIDR=%s",
			sanitizeID(key.GetRevNATID(), sanitizeIDs),
			key.GetCIDR(),
		))
	}
	if err := lbmaps.DumpSourceRange(srcRangeCB); err != nil {
		panic(err)
	}

	sort.Strings(out)
	return
}

// sanitizeTables clears non-deterministic data in the table output such as timestamps.
func sanitizeTables(dump []byte) []byte {
	r := regexp.MustCompile(`\([^\)]* ago\)`)
	return r.ReplaceAll(dump, []byte("(??? ago)"))
}

func checkTablesAndMaps(db *statedb.DB, writer *Writer, maps lbmaps, testDataPath string) bool {
	allDone := true
	count := 0
	for fe := range writer.Frontends().All(db.ReadTxn()) {
		if fe.Status.Kind != reconciler.StatusKindDone {
			allDone = false
		}
		count++
	}
	if count == 0 || !allDone {
		return false
	}

	var tableBuf bytes.Buffer
	writer.DebugDump(db.ReadTxn(), &tableBuf)
	actualTables := tableBuf.Bytes()

	var expectedTables []byte
	if expectedData, err := os.ReadFile(path.Join(testDataPath, "expected.tables")); err == nil {
		expectedTables = expectedData
	}
	actualTables = sanitizeTables(actualTables)
	expectedTables = sanitizeTables(expectedTables)

	os.WriteFile(path.Join(testDataPath, "actual.tables"), actualTables, 0644)

	var expectedMaps []mapDump
	if expectedData, err := os.ReadFile(path.Join(testDataPath, "expected.maps")); err == nil {
		expectedMaps = strings.Split(strings.TrimSpace(string(expectedData)), "\n")
	}
	actualMaps := dump(maps, frontendAddrs[0], true)

	actualPath := path.Join(testDataPath, "actual.maps")
	os.WriteFile(
		actualPath,
		[]byte(strings.Join(actualMaps, "\n")+"\n"),
		0644,
	)
	return bytes.Equal(actualTables, expectedTables) && slices.Equal(expectedMaps, actualMaps)
}

func logDiff(t *testing.T, fileA, fileB string) {
	t.Helper()

	contentsA, err := os.ReadFile(fileA)
	require.NoError(t, err)
	contentsB, _ := os.ReadFile(fileB)

	diff := difflib.UnifiedDiff{
		A:        difflib.SplitLines(string(contentsA)),
		B:        difflib.SplitLines(string(contentsB)),
		FromFile: fileA,
		ToFile:   fileB,
		Context:  2,
	}
	text, _ := difflib.GetUnifiedDiffString(diff)
	if len(text) > 0 {
		t.Logf("\n%s", text)
	}
}
